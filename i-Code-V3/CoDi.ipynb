{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGuptBqpnw_v",
    "outputId": "7f77c909-ade2-4544-d704-bcc6051c3f58"
   },
   "outputs": [],
   "source": [
    "!git https://github.com/simsim314/i-Code.gits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9RugJLi1n5nP",
    "outputId": "43313146-75ec-4ca2-cfcb-a7a6f5115512"
   },
   "outputs": [],
   "source": [
    "%cd i-Code/i-Code-V3/\n",
    "!pip install -r requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Laws7G3Fq_be",
    "outputId": "3de00268-7b89-4b1f-f9e7-0b0e55795429"
   },
   "outputs": [],
   "source": [
    "!wget https://huggingface.co/ZinengTang/CoDi/resolve/main/CoDi_audio_diffuser_m.pth\n",
    "!wget https://huggingface.co/ZinengTang/CoDi/resolve/main/CoDi_encoders.pth\n",
    "!wget https://huggingface.co/ZinengTang/CoDi/resolve/main/CoDi_text_diffuser.pth\n",
    "!wget https://huggingface.co/ZinengTang/CoDi/resolve/main/CoDi_video_diffuser_8frames.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFBIcYJjno05"
   },
   "source": [
    "<a id='ContentList'></a>\n",
    "# Content List\n",
    "\n",
    "## Single to Single Generation\n",
    "\n",
    "### 1. [Text To Image](#TextToImage)\n",
    "\n",
    "### 2. [Image To Text](#ImageToText)\n",
    "\n",
    "### 3. [Text To Audio](#TextToAudio)\n",
    "\n",
    "### 4. [Audio To Text](#AudioToText)\n",
    "\n",
    "### 5. [Image To Audio](#ImageToAudio)\n",
    "\n",
    "### 6. [Audio To Image](#AudioToImage)\n",
    "\n",
    "### 7. [Text To Video](#TextToVideo)\n",
    "\n",
    "## Multi-Conditioning Generation\n",
    "\n",
    "### 1. [Text + Image + Audio To Image](#TextImageAudioToImage)\n",
    "\n",
    "## Joint Multimodal Generation\n",
    "\n",
    "### 1. [Text To Image+Text](#TextToImageText)\n",
    "\n",
    "### 2. [Text To Video+Audio](#TextToVideoAudio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xSujprTno07"
   },
   "source": [
    "<a id='LoadModel'></a>\n",
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9VHwniono08",
    "outputId": "71f0122b-78e0-4596-f9b6-a5d82ea9f257",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load model from checkpoint.\n",
    "\n",
    "For model inference:\n",
    "The outputs are stored in an array as [number of output modalities, number of samples]\n",
    "If I generate 4 samples of image + caption, the shape would be [2, 4]\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from core.models.model_module_infer import model_module\n",
    "\n",
    "model_load_paths = ['CoDi_encoders.pth', 'CoDi_text_diffuser.pth', 'CoDi_audio_diffuser_m.pth', 'CoDi_video_diffuser_8frames.pth']\n",
    "inference_tester = model_module(data_dir='', pth=model_load_paths)\n",
    "inference_tester = inference_tester.cuda()\n",
    "inference_tester = inference_tester.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwhNEBPnno09"
   },
   "source": [
    "<a id='TextToImage'></a>\n",
    "# Text To Image\n",
    "### [Back to Menu](#ContentList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50Wv5ckEno0-",
    "outputId": "3bd0dd47-e7c0-4d36-cafa-661b0f70c001"
   },
   "outputs": [],
   "source": [
    "# Give a prompt\n",
    "prompt = \"cat wearing napolen clothes eating cheese\"\n",
    "# Generate image\n",
    "images = inference_tester.inference(\n",
    "                xtype = ['image'],\n",
    "                condition = [prompt],\n",
    "                condition_types = ['text'],\n",
    "                n_samples = 1,\n",
    "                image_size = 256,\n",
    "                ddim_steps = 100)\n",
    "images[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zi-yPL06no0-"
   },
   "source": [
    "<a id='ImageToText'></a>\n",
    "# Image To Text\n",
    "### [Back to Menu](#ContentList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D6lzCGntno0_",
    "outputId": "1b072ae1-21cb-43c0-a149-6a26f931038c"
   },
   "outputs": [],
   "source": [
    "# Load an image input\n",
    "from PIL import Image\n",
    "im = Image.open('./assets/demo_files/house.jpeg').resize((224,224))\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uUtzokjuno0_",
    "outputId": "3221135e-3769-42ff-c352-2e0ca2a84e37"
   },
   "outputs": [],
   "source": [
    "text = inference_tester.inference(\n",
    "                xtype = ['text'],\n",
    "                condition = [im],\n",
    "                condition_types = ['image'],\n",
    "                n_samples = 4,\n",
    "                ddim_steps = 50,\n",
    "                scale = 7.5,)\n",
    "text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmGJZKjhno0_"
   },
   "source": [
    "<a id='TextToAudio'></a>\n",
    "# Text To Audio\n",
    "### [Back to Menu](#ContentList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUHOCry4no1A",
    "outputId": "35e34cc3-bd8c-4355-c342-ea574a22f969",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Give a prompt\n",
    "prompt = 'a train enters station.'\n",
    "\n",
    "# Generate audio\n",
    "audio_wave = inference_tester.inference(\n",
    "                xtype = ['audio'],\n",
    "                condition = [prompt],\n",
    "                condition_types = ['text'],\n",
    "                scale = 7.5,\n",
    "                n_samples = 1,\n",
    "                ddim_steps = 50)[0]\n",
    "\n",
    "# Play the audio\n",
    "from IPython.display import Audio\n",
    "Audio(audio_wave.squeeze(), rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VwBO-XCno1A"
   },
   "source": [
    "<a id='AudioToText'></a>\n",
    "# Audio To Text\n",
    "### [Back to Menu](#ContentList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oEFcUjztno1A",
    "outputId": "1ef0740e-2d3e-4d20-8a0d-611288f634a6"
   },
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "from IPython.display import Audio\n",
    "\n",
    "path = './assets/demo_files/train_sound.flac'\n",
    "\n",
    "audio_wavs, sr = torchaudio.load(path)\n",
    "audio_wavs = torchaudio.functional.resample(waveform=audio_wavs, orig_freq=sr, new_freq=16000).mean(0)[:int(16000 * 10.23)]\n",
    "Audio(audio_wavs.squeeze(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPGHghCjno1B",
    "outputId": "695ca474-88c8-41ea-dca0-2921fcb132e6"
   },
   "outputs": [],
   "source": [
    "n_samples = 4\n",
    "text = inference_tester.inference(\n",
    "                xtype = ['text'],\n",
    "                condition = [audio_wavs],\n",
    "                condition_types = ['audio'],\n",
    "                n_samples = n_samples,\n",
    "                ddim_steps = 50,\n",
    "                scale = 7.5)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKS2uZjbno1B"
   },
   "source": [
    "<a id='ImageToAudio'></a>\n",
    "# Image To Audio\n",
    "### [Back to Menu](#ContentList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3utd47O2no1B",
    "outputId": "744024cb-940f-4233-97cb-d40aa6662dfa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load an image\n",
    "from PIL import Image\n",
    "from core.common.utils import regularize_image\n",
    "im = Image.open('./assets/demo_files/rain_on_tree.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8T4W6gaKno1B",
    "outputId": "90369bbc-a55f-4c62-ad6d-043159f73750"
   },
   "outputs": [],
   "source": [
    "# Generate audio\n",
    "audio_wave = inference_tester.inference(\n",
    "                xtype = ['audio'],\n",
    "                condition = [im],\n",
    "                condition_types = ['image'],\n",
    "                scale = 7.5,\n",
    "                n_samples = 1,\n",
    "                ddim_steps = 50)[0]\n",
    "\n",
    "# Play audio\n",
    "from IPython.display import Audio\n",
    "Audio(audio_wave.squeeze(), rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_IVYCHtno1C"
   },
   "source": [
    "<a id='AudioToImage'></a>\n",
    "# Audio To Image\n",
    "### [Back to Menu](#ContentList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7l_3QiwNno1C",
    "outputId": "b6626050-bcda-419c-bbb0-f45277cda6e7"
   },
   "outputs": [],
   "source": [
    "# Load input audio andplay\n",
    "import torchaudio\n",
    "import torch\n",
    "from IPython.display import Audio\n",
    "pad_time = 10.23\n",
    "\n",
    "path = './assets/demo_files/wind_chimes.wav'\n",
    "\n",
    "audio_wavs, sr = torchaudio.load(path)\n",
    "audio_wavs = torchaudio.functional.resample(waveform=audio_wavs, orig_freq=sr, new_freq=16000).mean(0)[:int(16000 * pad_time)]\n",
    "padding = torch.zeros([int(16000 * pad_time) - audio_wavs.size(0)])\n",
    "audio_wavs = torch.cat([audio_wavs, padding], 0)\n",
    "\n",
    "from IPython.display import Audio\n",
    "Audio(path, rate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1iEK5_OFno1C",
    "outputId": "267b8652-229f-48b9-88b2-99877776c36a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Generate image\n",
    "images = inference_tester.inference(\n",
    "                xtype = ['image'],\n",
    "                condition = [audio_wavs],\n",
    "                condition_types = ['audio'],\n",
    "                scale = 7.5,\n",
    "                image_size = 256,\n",
    "                ddim_steps = 50)\n",
    "images[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xWWnfyYno1D"
   },
   "source": [
    "<a id='TextToVideo'></a>\n",
    "# Text To Video\n",
    "### [Back to Menu](#ContentList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swxIHi5Yno1D",
    "outputId": "61bc8c98-9fb5-47ba-b160-918a2c993f07"
   },
   "outputs": [],
   "source": [
    "# Give A Prompt\n",
    "prompt = 'people having meal in a ancy resrtourant'\n",
    "\n",
    "n_samples = 1\n",
    "outputs = inference_tester.inference(\n",
    "                ['video'],\n",
    "                condition = [prompt],\n",
    "                condition_types = ['text'],\n",
    "                n_samples = 1,\n",
    "                image_size = 256,\n",
    "                ddim_steps = 50,\n",
    "                num_frames = 8,\n",
    "                scale = 7.5)\n",
    "\n",
    "video = outputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKAKDhGXno1D",
    "outputId": "696f70d5-92da-489a-fb25-afa84aa46b51"
   },
   "outputs": [],
   "source": [
    "# Visual video as gif\n",
    "from PIL import Image\n",
    "frame_one = video[0]\n",
    "path = \"./generated_text2video.gif\"\n",
    "frame_one.save(path, format=\"GIF\", append_images=video[1:],\n",
    "               save_all=True, duration=2000/len(video), loop=0)\n",
    "\n",
    "from IPython import display\n",
    "from IPython.display import Image\n",
    "Image(data=open(path,'rb').read(), format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMAyAiHSno1D"
   },
   "source": [
    "<a id='TextImageAudioToImage'></a>\n",
    "#  Text + Audio To Image\n",
    "\n",
    "### [Back to Menu](#ContentList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qe66SQjPno1E",
    "outputId": "1290d8c7-6d7b-4ef1-85a7-879050b21981"
   },
   "outputs": [],
   "source": [
    "# Load Audio Inputs\n",
    "import torchaudio\n",
    "import torch\n",
    "from IPython.display import Audio\n",
    "\n",
    "path = './assets/demo_files/sea_waves.wav'\n",
    "\n",
    "audio_wavs, sr = torchaudio.load(path)\n",
    "audio_wavs = torchaudio.functional.resample(waveform=audio_wavs, orig_freq=sr, new_freq=16000).mean(0)[:int(16000 * 10.23)]\n",
    "Audio(audio_wavs.squeeze(), rate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARRtkZykno1E",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Give A Prompt\n",
    "prompt = 'dawn, dawn scenery, sunset, beautiful lighting.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udelZkM7no1E",
    "outputId": "c7aa5932-cf72-430a-b276-22e8d5cddaef"
   },
   "outputs": [],
   "source": [
    "# Generate image\n",
    "# Mix weight here is the weighting ratio of the condition inputs\n",
    "\n",
    "n_samples = 1\n",
    "images = inference_tester.inference(\n",
    "                ['image'],\n",
    "                condition = [audio_wavs, prompt],\n",
    "                condition_types = ['audio', 'text'],\n",
    "                n_samples = n_samples,\n",
    "                image_size = 256,\n",
    "                mix_weight = {'audio': 1, 'text': 2}, )\n",
    "\n",
    "images[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQOmN26_no1E"
   },
   "source": [
    "<a id='TextToImageText'></a>\n",
    "#  Text To Image + Text\n",
    "\n",
    "### [Back to Menu](#ContentList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ke4UeqsGno1E",
    "outputId": "dff54c06-cce3-40a5-d9d6-8cc99d0d9cc4"
   },
   "outputs": [],
   "source": [
    "# Give A Prompt\n",
    "prompt = 'deep diving in coral reef underwater.'\n",
    "\n",
    "outputs = inference_tester.inference(\n",
    "                ['image', 'text'],\n",
    "                condition = [prompt],\n",
    "                condition_types = ['text'],\n",
    "                n_samples = 1,\n",
    "                image_size = 256)\n",
    "\n",
    "image, text = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhlrgurDno1F",
    "outputId": "db947f06-5100-4cb9-9746-a0fa225e83ec"
   },
   "outputs": [],
   "source": [
    "image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7fboJrTno1F",
    "outputId": "77541166-51e0-4c72-e96f-347086bb6cc0"
   },
   "outputs": [],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlGsxNNbno1F"
   },
   "source": [
    "<a id='TextToVideoAudio'></a>\n",
    "#  Text To Video + Audio\n",
    "\n",
    "### [Back to Menu](#ContentList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktKfRU_uno1F",
    "outputId": "14159878-8c09-4b02-c04a-14adfc2b4faf"
   },
   "outputs": [],
   "source": [
    "# Give A Prompt\n",
    "prompt = 'walking inside a beautiful forest, nature, birds.'\n",
    "\n",
    "n_samples = 1\n",
    "outputs = inference_tester.inference(\n",
    "                ['video', 'audio'],\n",
    "                condition = [prompt],\n",
    "                condition_types = ['text'],\n",
    "                n_samples = 1,\n",
    "                image_size = 256,\n",
    "                ddim_steps = 50,\n",
    "                num_frames = 8,\n",
    "                scale = 7.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0joO63NIno1G",
    "outputId": "4e47fa10-b94c-4c56-dd51-6c2cbc551fbf"
   },
   "outputs": [],
   "source": [
    "video, audio_wave = outputs\n",
    "\n",
    "from IPython.display import Audio\n",
    "Audio(audio_wave[0].squeeze(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ls3MU48fno1G",
    "outputId": "b8925881-3e3c-4794-a08b-2510594a79a0"
   },
   "outputs": [],
   "source": [
    "# Visual video as gif\n",
    "video = video[0]\n",
    "from PIL import Image\n",
    "frame_one = video[0]\n",
    "path = \"./generated_video.gif\"\n",
    "frame_one.save(path, format=\"GIF\", append_images=video[1:],\n",
    "               save_all=True, duration=2000/len(video), loop=0)\n",
    "\n",
    "from IPython import display\n",
    "from IPython.display import Image\n",
    "Image(data=open(path,'rb').read(), format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPZ5CtE8no1G"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
